{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee65c42",
   "metadata": {},
   "source": [
    "# Computer Vision Course Project\n",
    "# Project Title: Indoor Object Detection (Chair, Sofa, Wardrobe)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce72ec14",
   "metadata": {},
   "source": [
    "Group Members:\n",
    "Name                           Roll Number    GR Number\n",
    "Atharva Chaudhari                  62          11910101      \n",
    "Shubham Damale                     68          11910803\n",
    "Chinmay Deotale                    71          11910759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba56765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "import pandas as pd              \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  \n",
    "import PIL       \n",
    "import PIL.Image\n",
    "import os       \n",
    "import os.path\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "from scipy.stats import stats\n",
    "import pickle\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer   # to normalize sift feature extracted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243848c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('model/SVM_OVR_RBF.sav', 'rb')\n",
    "model = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22cdd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previously dumped hog image dataset \n",
    "pickle_in = open('model/kmeans1.sav', 'rb')\n",
    "kmeans = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d264f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previously dumped hog image dataset \n",
    "pickle_in = open('model/PCA1.sav', 'rb')\n",
    "PCA = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93184548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 2 0 0 0 2 0 0 0 0 2 0 2 0 2 0\n",
      " 0 2 2 0 2 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 2 0 1 0 0 0 2 2 0 0 1 0\n",
      " 2 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 2 0 0 0 2 1 0 1 0 2 2 1 1 0 0 0 1 0\n",
      " 2 0 2 1 0 1 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0\n",
      " 0 0 2 1 0 1 0 2 0 0 0 1 0 0 1 0 2 0 0 0 2 2 2 0 1 0 0 0 2 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 1 0 0 0 0 0 2 2 0 0 1 0\n",
      " 2 0 0 1 0 2 0 0 0 0 0 2 1 0 0 1 2 0 0 0 0 1 0 0 0 2 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 2 2 2 0 0 2 1 0 0 0 0 0 0 0 2 0 2 0 0 0 0 2 0 0 0 0 0 2 2 0 0 0 0 2 0\n",
      " 0 0 0 2 0 0 0 0 0 0 1 0 0 1 0 0 0 2 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 2 0 0 2 0 0 1 0 0 2 2 0 0 0 2 2 0 0 0 1 0 0 0 2 1 0 0 0 0 1 0 1 0 0\n",
      " 0 2 2 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 2 0 1 2 0 0 2\n",
      " 0 0 0 2 0 0 2 0 0 0 2 0 0 0 0 1 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 2 0 0 0 0 0 2 1 0 0 0 0 0 0 2 0 0 2 0 0 2 0 2 1 0 0 2 1 0 0 0 1 0 0\n",
      " 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 1 2 0 1 0 0 2 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 2 0 1 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 2 0 0 2 0 2\n",
      " 0 2 2 2 0 0 1 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1 1 0 0 0 2 1 0 2 2 1 0 0\n",
      " 0 2 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 2 1 0 1 1 1 1 2\n",
      " 0 2 1 0 0 0 0 0 1 1 0 2 2 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 2 0 2 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 2 2 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 2 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 2 0 0 2\n",
      " 2 1 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 2 1 0 0 1 2\n",
      " 0 0 2 0 0 0 0 0 0 1 2 0 0 0 0 1 2 0 0 0 0 0 0 0 2 0 2 0 2 2 2 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 1 0 1 1 0 1 0 0 0 0 2 0 0 0 0 0 0 1 0 1 0 0 2 2 0 1\n",
      " 0 0 0 0 0 0 2 0 0 0 2 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 0\n",
      " 0]\n",
      "sofa : 124\n",
      "chair : 735\n",
      "wadrobe : 141\n"
     ]
    }
   ],
   "source": [
    "b=r'D:\\A71_CHINMAY\\sem5\\cv\\course_project\\Dataset\\positive\\chair'\n",
    "data =[]\n",
    "for filename in os.listdir(b):\n",
    "    \n",
    "    path=os.path.join(b,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize imageAC\n",
    "    resize=(400,400)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.float)\n",
    "\n",
    "    a=kmeans.predict(array_double) \n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5,6,7,8])\n",
    "    data.append(hist[0])\n",
    "\n",
    "norm = Normalizer()\n",
    "normalized = norm.fit_transform(data)  \n",
    "normalized.shape# normalize \n",
    "\n",
    "Standardize = StandardScaler()\n",
    "x_scaled = Standardize.fit_transform(normalized)\n",
    "pd.DataFrame(normalized)\n",
    "x_scaled.shape\n",
    "\n",
    "x_pca = PCA.transform(x_scaled)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca\n",
    "\n",
    "# First 100 images are of chairs\n",
    "m = x_pca.iloc[:1000,:]\n",
    "#prediction\n",
    "y_pred1 = model.predict(m)\n",
    "\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)\n",
    "a=np.count_nonzero(y_pred1==1)\n",
    "print(\"sofa :\",a)\n",
    "a=np.count_nonzero(y_pred1==0)\n",
    "print(\"chair :\",a)\n",
    "a=np.count_nonzero(y_pred1==2)\n",
    "print(\"wadrobe :\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a1e6a",
   "metadata": {},
   "source": [
    "chair-> 73.5 % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142ee68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 2 2 1 1 0 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 2 1 1 1 0 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1 0 1 1 1 1 1 1 0\n",
      " 1 2 1 0 1 1 2 0 1 2 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 2 1 1 1 0 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 2 1 1 1 1 0 2 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 2 1 1 0 2 1 2 1 1 1 2\n",
      " 1 1 1 1 1 1 1 2 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 2 2 1 1 2 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 0 1 1 1 1 2 1 0 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 0 1 1 2 1 0 1 0 1 1 1 1 2 1 1 0 0 2 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 2 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 0 1 0 1 2 1 1 1 1 1 1 2 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 0 0 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1 1 1 1 0 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 2 1 1 0 2 1 1 1 2 1 1 1 1 2 0 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 2 1 0 1 1 1 0 1 1 1 2 1 1 1 2 1 1\n",
      " 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 0 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 2 1 1 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 2 1 0 1 1 2 1 2 1 1 1 0 1 1 0 1 1 1 1 2 1 1 1 1 1 1 1 0 2 1 0 1\n",
      " 1]\n",
      "sofa : 815\n",
      "chair : 87\n",
      "wadrobe : 98\n"
     ]
    }
   ],
   "source": [
    "b=r'D:\\A71_CHINMAY\\sem5\\cv\\course_project\\Dataset\\positive\\sofa'\n",
    "data =[]\n",
    "for filename in os.listdir(b):\n",
    "    \n",
    "    path=os.path.join(b,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize imageAC\n",
    "    resize=(400,400)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.float)\n",
    "\n",
    "    a=kmeans.predict(array_double) \n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5,6,7,8])\n",
    "    data.append(hist[0])\n",
    "\n",
    "norm = Normalizer()\n",
    "normalized = norm.fit_transform(data)  \n",
    "normalized.shape# normalize \n",
    "\n",
    "Standardize = StandardScaler()\n",
    "x_scaled = Standardize.fit_transform(normalized)\n",
    "pd.DataFrame(normalized)\n",
    "x_scaled.shape\n",
    "\n",
    "x_pca = PCA.transform(x_scaled)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca\n",
    "\n",
    "# First 100 images are of chairs\n",
    "m = x_pca.iloc[:1000,:]\n",
    "#prediction\n",
    "y_pred1 = model.predict(m)\n",
    "\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)\n",
    "a=np.count_nonzero(y_pred1==1)\n",
    "print(\"sofa :\",a)\n",
    "a=np.count_nonzero(y_pred1==0)\n",
    "print(\"chair :\",a)\n",
    "a=np.count_nonzero(y_pred1==2)\n",
    "print(\"wadrobe :\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64697278",
   "metadata": {},
   "source": [
    "Sofa ->81.5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7227c0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 1 2 2 0 2 2 1 2 2 2 1 2 2 2 2 2 2 2 0 1 2 1 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 1 2 2 2 2 0 2 2 1 2 2 2 1 2 1 2 2 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1\n",
      " 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 0 2 0\n",
      " 2 2 0 0 2 2 0 2 2 0 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 0 0 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 1 2 2 2 2 2 2 1 2 2 2 2 1 2 2 1 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 1 2\n",
      " 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 1\n",
      " 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 0 2 0 1 1 2 0 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 0 2 2 0 1 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 0 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2\n",
      " 0 0 2 0 2 2 2 2 2 2 2 2 2 2 0 0 1 2 2 2 2 1 2 2 2 2 0 2 0 1 2 2 2 2 2 2 2\n",
      " 1 2 2 1 2 2 2 2 0 2 1 2 1 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 2 0 2 2 2 0 2 1 2 2 1 1 2 2 0 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 0 2 2 2 2 2 2 0\n",
      " 2 0 2 2 2 1 2 2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 2 0 2 2 1 2 2 2 2 2 0 1 2 2 1 2 0 0 2 2 2 2 0 1 2 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 1 2 2 2 1 2 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2 1 2 2 0 2 2 2 2 2 2 2 1 2 2 2\n",
      " 2 1 2 1 2 2 2 1 2 2 2 2 2 2 1 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 0 2 2 2 2 1 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2\n",
      " 2 2 0 2 2 1 2 1 0 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 1 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2]\n",
      "sofa : 107\n",
      "chair : 69\n",
      "wadrobe : 824\n"
     ]
    }
   ],
   "source": [
    "b=r'D:\\A71_CHINMAY\\sem5\\cv\\course_project\\Dataset\\positive\\wadrobe'\n",
    "data =[]\n",
    "for filename in os.listdir(b):\n",
    "    \n",
    "    path=os.path.join(b,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize imageAC\n",
    "    resize=(400,400)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.float)\n",
    "\n",
    "    a=kmeans.predict(array_double) \n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5,6,7,8])\n",
    "    data.append(hist[0])\n",
    "\n",
    "norm = Normalizer()\n",
    "normalized = norm.fit_transform(data)  \n",
    "normalized.shape# normalize \n",
    "\n",
    "Standardize = StandardScaler()\n",
    "x_scaled = Standardize.fit_transform(normalized)\n",
    "pd.DataFrame(normalized)\n",
    "x_scaled.shape\n",
    "\n",
    "x_pca = PCA.transform(x_scaled)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca\n",
    "\n",
    "# First 100 images are of chairs\n",
    "m = x_pca.iloc[:1000,:]\n",
    "#prediction\n",
    "y_pred1 = model.predict(m)\n",
    "\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)\n",
    "a=np.count_nonzero(y_pred1==1)\n",
    "print(\"sofa :\",a)\n",
    "a=np.count_nonzero(y_pred1==0)\n",
    "print(\"chair :\",a)\n",
    "a=np.count_nonzero(y_pred1==2)\n",
    "print(\"wadrobe :\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aaaeed",
   "metadata": {},
   "source": [
    "wardrobe -> 82.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fdd5f",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------- THANK - YOU -----------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
